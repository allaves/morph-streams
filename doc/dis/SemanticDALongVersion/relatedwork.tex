\section{Related Work}
\label{sec:related-work}

%Several systems exist to provide ontology-based access to stored data, mainly in the form of relational databases, as described in \cite{Sahoo_09}. 
In this section we provide details about related work on the areas of relational-to-\rdf data access, streaming data querying and \rdf streams.

\subsection{Relational-To-\rdf Data Access}
\label{sec:rdbtordf}
The realization of the Semantic Web vision, where data is available, understandable and processable by computers, has launched several initiatives that aim at providing semantic access to traditional data sources.
Most stored data in the web is currently preserved in relational databases and it has therefore become a need to generate Semantic Web content from them \cite{Sahoo_09}. In this context there is a considerably large amount of research in the community, with the goal of exposing data in terms of ontologies that formally express a domain of interest \cite{Poggi_08}. This is the goal of Ontology-based data access (OBDA).
%Most of the approaches attempt to provide some kind of mapping from a relational concept to a concept in an ontological model.
%
%Many problems arise when dealing with model mismatch issues, query interpretation, semantic reasoning, etc.
As aforementioned, most of the existing approaches are based on the exploitation of mappings between the relational (rows and columns) and the ontological (classes and properties) models. Some of them use their own languages to define
these mappings, while others use \sparql extensions or \sql expressions.
%OBDA systems use these kinds of mappings between an ontology and the different data sources.
In all cases, the objective of these systems is to allow constructing ontology-based queries (e.g. in \sparql), which
are then rewritten into a set of queries expressed in the query language of the data source (typically \sql), according
to the specified mappings. The query results are then converted back from the relational format into \rdf, which is returned to the user.

One common approach is to first generate a syntactical translation of the database schema to an ontological representation. Although the resulting ontology has no real semantics, it may be argued that this is a first step through an ontology model and that ontology alignment techniques could be used later to map it to a real domain ontology \cite{Lubyte_09}. Variations of ontology generation and syntactic mappings have been presented in previous works \cite{Seaborne_07,Cerbah_08,Laborda_06,Prudhommeaux_07}.
In SquirrelRDF \cite{Squirrell_06} they take this simple approach. A mapping generated from the relational database schema is built in \rdf. There is no mapping to a mediated ontology. \sparql queries can be executed and results are return in \rdf.

An additional step is taken in RDBToOnto \cite{Cerbah_08} , where the ontology generation process does not only take the database schema into account, but also the data. For instance it is able to discover subsumption relationships by finding categorization columns in the database tables. Even after this resulting ontology is produced, RDBToOnto allows users to create custom constraints. However this work focuses on the ontology generation and does not provide a querying mechanism to the database data.
Relational.OWL \cite{Laborda_06} builds an ontology based on the relational schema and then maps it to the mediated ontology through a \rdf query language. The first phase -transforming the database schema to the Relational.OWL ontology- produces a syntactical representation without real semantics. It is thus necessary to proceed with the second step, mapping the Relational.OWL representation to the domain ontology. This mapping can be done with an \rdf query language like \sparql and it is therefore not necessary to create a new mapping language.
The SPASQL implementation \cite{Prudhommeaux_07} is an extension for MySQL to support \sparql queries. It is thus technologically restricted to MySQL as it uses its query engine, although similar extensions could be built for other DBMSs. This extension is able to parse \sparql queries and compile them and directly execute them in the MySQL engine. The mapping is limited (e.g. no multi-field keys allowed) and it is not formalized.

Although automatic generation of ontologies and mappings can be useful in simple scenarios, for complex ones it is a limited approach. User expert knowledge may become necessary for complex mapping definitions, but it is also necessary to provide well defined languages that express those mappings. A number of OBDA systems use these mapping languages to 
access the underlying relational data sources \cite{Sahoo_09}.

The Virtuoso \cite{Erling_07} declarative meta-schema language allows mapping relational schemas to \rdf ontologies and is based on Quad Map Patterns that define the transformations. In the \dtworq platform \cite{Bizer_07}, the \dtworq language is introduced and formally defined by an \rdf schema and its engine is implemented as a Jena graph. It provides a Jena or Sesame API plug-in for querying and reasoning that rewrites the API calls to \sql queries which are executed in the database server, using the mappings. MASTRO \cite{Poggi_07} is a OBDA system that works with ontologies whose data is accessed through mappings in an external source, i.e. using an OBDA-enabled reasoner. It works over the DL-Lite${}_A$ language, a fragment of OWL-DL. The mappings are specified through assertions that include \sql queries over the database. The expressiveness of the queries is limited to conjunctive queries (CQ).
%The Virtuoso [EM07] declarative meta-schema language allows mapping relational schemas to RDF ontologies. SPARQL queries posed to the system are mapped to relational databases. The meta-schema is based on Quad Map Patterns that define transformations from relational columns into triples that match a SPARQL pattern. Notice that Virtuoso includes extensions to SPARQL for aggregates (COUNT, MIN, MAX, AVG, SUM) and it also allows SPARQL sub-queries.
%In the D2RQ platform [BC07], a specific mapping language is introduced (D2RQ language) and formally defined by an RDF schema. The mapping defines relationships between an ontology and a relational database schema. The D2RQ Engine is implemented as a Jena graph. It provides a Jena or Sesame API plug-in for querying and reasoning with RDF. This plug-in rewrites thee API calls to SQL queries which are executed in the database server, using the mappings. Results are returned as RDF triples.
%In [PLC+08] they propose MASTRO, a DL reasoner for ontologies whose data is accessed through mappings in an external source, i.e. an ODBA-enabled reasoner. The reasoner works over the DL-LiteA language, a fragment of OWL-DL. The mappings are specified through assertions that include SQL queries over the database. The language in this work is well formalized and the query answering complexity is well explored. The expressivity of the queries is limited to conjunctive queries (CQ). An implementation of a plug-in for data access to relational databases through SPARQL queries has also been built using this approach [PRR08].
%The R2O language [BCG05] provides formal mappings from relational databases to %ontologies. The ODEMapster System uses this language to execute queries on the %ontology that are translated to SQL to get results from the relational source.
\bigskip

There are two main alternative approaches for defining these kinds of mappings \cite{Lenzerini_02}, \textit{Local-as-view (LaV)}
and \textit{Global-as-view (GaV)}, and a combination of both, \textit{GLAV}. In the LaV approach, each of the source
schemas is represented as a view in terms of the global schema.
%If our system $\mathcal{I}$ is represented as: $\mathcal{I = <G,S,M>}$, where $\mathcal{G}$ is the global schema, $\mathcal{S}$ is a source schema and $\mathcal{M}$ is the mapping between $\mathcal{G}$ and $\mathcal{S}$, then the mapping assertions in $\mathcal{M}$ will be a set of elements of the form: $s \leadsto q_{\mathcal{G}}$
%where $s$ is an element of $\mathcal{S}$ and $q_{\mathcal{G}}$ is a query over the global schema $\mathcal{G}$.
This approach is useful if the global schema is well established or if the set of sources or their schemas may constantly change.
%Notice that changes in the sources do not affect the global schema.
However, query processing in this approach is not obvious, as it is not explicitly stated in the mapping definition how
to obtain the data from the global view.
%Query rewriting techniques such as query answering using views can be used in this approach \cite{Halevy_01}.
In the GaV approach, the global schema elements are represented as views over the source schemas and it is explicitly defined how to query the sources. The advantage is that the processor can directly use this information to perform the query rewriting. The main disadvantage is that mapping definitions are affected in case of changes in the set of sources or in any of their schemas.  % to obtain the desired information in terms of the global schema. %Following the system representation $\mathcal{I = <G,S,M>}$, in the GAV approach the mapping assertions are elements of the form:
%$g \leadsto q_{\mathcal{S}}$
%Where $g$ is an element of the global schema $\mathcal{G}$ and is expressed as a view $q_{\mathcal{S}}$, a query on the source schema.
%The advantage is that the mapping itself already indicates how to query the sources to obtain the data, so the processor can directly use this information to perform the query rewriting. The main disadvantage is that mappings definitions are affected in case of changes or additions to the sources schemas.%, the global schema may suffer changes and this may affect other mapping definitions.



%A simple approach is to first generate a syntactical translation of the database schema to an ontological representation. Although the resulting ontology has no real semantics, it may be argued that this is a first step through an ontology model and could later be mapped to a real domain ontology \cite{Lubyte_09}.
%Virtuoso \cite{Erling_07} and \dtworq  \cite{Bizer_07}, like \rtwoo, use mappings between the source relational schema to \rdf ontologies enabling users to issues queries over a semantically rich domain ontology.
%MASTRO \cite{Poggi_07} is a OBDA system that works with ontologies whose data is accessed through mappings in an external source, i.e. using an OBDA-enabled reasoner. 
%It works over the \textit{DL-Lite$_\mathcal{A}$} language, a fragment of OWL-DL. 
%The mappings are specified through assertions that include \sql queries over the database.
%The expressiveness of the queries supported by these systems is limited to conjunctive queries, and none of the approaches takes into account streaming data and continuous queries.

\subsubsection{Streaming Data Querying}
\label{sec:str_data_query} 


Several Stream processing and query engines have been built in the past years and can be grouped in two main areas: event stream systems (e.g. Aurora/Borealis \cite{Abadi_2005}, STREAM \cite{Arasu_06a}, TelegraphCQ \cite{Chandrasekaran_03}) and acquisitional stream systems (e.g. TinyDB \cite{Madden_05}, \snee \cite{Galpin_09}, Cougar \cite{Yao_02}). For the first, the stream system does not have control over the data arrival rate, which is often potentially high and usually unknown and the query optimization goal is to minimize latency. 
For acquisitional streams, it is possible to control when data is obtained from the source, typically a sensor network, and the query optimization goal is to maximize network lifetime. 

A number restrictions must be considered in the case of acquisitional streams from sensor networks, namely the usually low energy resources, limited computing power and storage capabilities of sensors. In order to address these issues, research has produced Sensor Networks Query Processing engines.% such as TinyDB, Cougar and SNEE.
These processors use declarative query languages for continuous data which describe logically the set of information that is to be collected but leaves to the engine to determine the algorithms and plans that are needed to get the data form the different nodes of the sensor network. Hence the server engine produces optimized query plans that are locally executed by the sensor network nodes in a distributed in-network scheme. These engines must also consider several optimization techniques in order to efficiently gather the information from the sensor nodes. This approach has been proved to be efficient especially in terms of energy consumption \cite{Madden_05}. Architectures for query optimization in these constrained scenarios have surfaced \cite{Galpin_09,Madden_05}, showing that even with such limitations it is still possible to use rich and expressive declarative query languages.

Some of these systems have their own stream query language generally based on \sql. Although \cql (Continuous Query Language) \cite{Arasu_2006} is the best known of these languages  there is still no common language for stream queries.
The \sneeql\cite{Brenninkmeijer_08} language for querying streaming data sources, which is used throughout the examples of this paper, is inspired by \cql, but it provides greater expressiveness in queries, including both event and acquisitional streams, and stored extents.
Our work does not aim to improve on relational stream query processing, but to enable these systems to be accessible via ontology-based querying.
%
% and although some standardisation attempts have surfaced \cite{Jain_08},
%The SNEEql [BGF+08] language for querying streaming data sources is based on the widely known CQL [ABW06], but it provides greater expressiveness in queries, including streams and relations, time and tuple windows, blocking and non-blocking operators, and pull and pushed based streams.
%
%In streaming data models the basic compound tuple type is defined as a set of typed attributes. A tagged tuple in a stream is a tuple that includes a named timestamp attribute.

\subsubsection{\rdf Streams}
\label{sec:rdfstream}





As it is described in Section \ref{sec:str_data_query} query languages for relational data streams have been proposed and implemented in recent years. These languages borrow much of relational query languages such as \sql. In ontology-based data access solutions, continuous queries are expected to be posed in terms of an ontological view. In order to do so, it is necessary to have a stream query language that natively supports semantic models \cite{DellaValle_09,Groppe_07}.

\sparql \cite{Prudhommeaux_2008} is the W3C Recommendation for a query language over \rdf. Even though  \sparql has been used to query \rdf triples annotated with time constructs and can be used to represent data coming from streaming sources, it currently lacks the necessary operators to effectively query streaming data.\
There are two main approaches in the literature for extending \sparql with stream-based operators: \streamingsparql and \csparql.
Both languages introduce extensions for the support of \rdf streams, and both define time-based and triple-based window operators where the upper bound is fixed to the current evaluation time. 

%\subsubsection{Streaming SPARQL.}

The \streamingsparql language presented in \cite{Bolles_08} is able to handle \rdf based data streams. The semantics of these extensions are also provided as well as the algorithm to map the language additions to the extended algebra. The grammar of \streamingsparql basically consists in adding the capability of defining time and tuple-based windows over streams which are defined in the \textsf{FROM} clause. % which are explicitly stated using the \textsf{STREAM} keyword. The windows are defined in the \textsf{FROM} section, using the \textsf{WINDOW} keyword. Both time-based and tuple based windows are supported. For time-based windows the \textsf{RANGE} keyword allows specifying the window size in time units. A \textsf{SLIDE} parameter can be specified to indicate the frequency of the window creation.
%For tuple-base windows the ELEMS keyword is used instead of RANGE.
This proposal also allows specifying windows on graph patterns, which complicates its evaluation semantics. %It doesn't provide aggregate functions.


The operators correspond to a large extent to the operators seen in DSMS query languages. % like CQL (see Section \ref{datastreams}).
Instead of tagged tuples we have tagged triples and the time and tuple based attributes are similar as well in syntax
and semantics. However, \streamingsparql still lacks support for many features such as windows with higher boundaries
different to the current timestamp $now$, aggregates, projection functions, and acquisitional parameters, among others.
In addition, \streamingsparql allows windows in group graph patterns and redefines the language semantics due to the
introduction of timestamps.

\csparql (Continuous \sparql) \cite{Barbieri2010An-Execution-En} also operates over \rdf streams, sequences of triples annotated with non-decreasing timestamps. It defines, as in \streamingsparql, both time or tuple-based sliding windows.
It allows combining stored and streaming knowledge and also combining multiple streams. 
\csparql offers aggregates, such as \textsf{COUNT, SUM, AVG, MIN} and \textsf{MAX}. 
The aggregate semantics introduced in \csparql follow an approach of extending the data, which differs from standard aggregation semantics of summarizing the data. We have opted to support the aggregation semantics being defined for \sparql 1.1 \cite{Harris2010SPARQL-1.1-Quer}, which summarize the data.


Unlike both previous approaches, the \sparqlstr windowing operator enables windows to be defined in the past so as to support correlation with historic data. 
We have not included triple-based windows in \sparqlstr due to the problems with their semantics, discussed in Section~\ref{streamingsparqlsyntax}.
Window-to-stream operators are also missing in both existing approaches, which provides ambiguous semantics for the language.
In \sparqlstr the result of a window operator is a bag to triples over which traditional operators can be applied.
We have introduced three window-to-stream operators inspired by \sneeql and \cql.



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "rere"
%%% End: 
